scala> import org.apache.spark.sql.types.StringType
import org.apache.spark.sql.types.StringType

scala> import org.apache.spark.sql.types.StructType
import org.apache.spark.sql.types.StructType

scala> import org.apache.spark.sql.types.StructField
import org.apache.spark.sql.types.StructField

scala> import org.apache.spark.sql.types.StringType
import org.apache.spark.sql.types.StringType

scala> import org.apache.spark.sql.types.DateType
import org.apache.spark.sql.types.DateType

scala> import org.apache.spark.sql.types.DoubleType
import org.apache.spark.sql.types.DoubleType

import org.apache.spark.sql.expressions.Window
import org.apache.spark.sql.expressions.Window



scala> var tschema = StructType(Array(
     | StructField("sid",StringType),
     | StructField("date",DateType),
     | StructField("mtype",StringType),
     | StructField("value",DoubleType)
     | ))
tschema: org.apache.spark.sql.types.StructType = StructType(StructField(sid,StringType,true), StructField(date,DateType,true), StructField(mtype,StringType,true), 
StructField(value,DoubleType,true))


Normal CSV:
==========

scala> var data2020 = spark.read.schema(tschema).option("dateFormat","yyyyMMdd").csv("livia/sparksql/2020.csv")
data2020: org.apache.spark.sql.DataFrame = [sid: string, date: date ... 2 more fields]


scala> var summary2020 = data2020.where(col("mtype")==="TMAX").withColumn("Max_value", max("value") over(Window.partitionBy(month(col("date"))).orderBy(col("value").desc))).groupBy(year(col("date")), month(col("date"))).agg(max(col("value")).as("ultimate_max_value")).orderBy(col("ultimate_max_value").desc)
summary2020: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [year(date): int, month(date): int ... 1 more field]

scala> summary2020.show
+----------+-----------+------------------+                                     
|year(date)|month(date)|ultimate_max_value|
+----------+-----------+------------------+
|      2020|          5|            2228.0|
|      2020|          8|             656.0|
|      2020|          1|             644.0|
|      2020|          4|             575.0|
|      2020|          7|             533.0|
|      2020|          6|             500.0|
|      2020|          3|             485.0|
|      2020|          9|             473.0|
|      2020|          2|             468.0|
+----------+-----------+------------------+

Time taken: 40 secs.


scala> var data2017 = spark.read.schema(tschema).option("dateFormat","yyyyMMdd").csv("livia/sparksql/2017.csv")
data2017: org.apache.spark.sql.DataFrame = [sid: string, date: date ... 2 more fields]


scala> var summary2017 = data2017.where(col("mtype")==="TMAX").withColumn("Max_value", max("value") over(Window.partitionBy(month(col("date"))).orderBy(col("value").desc))).groupBy(year(col("date")), month(col("date"))).agg(max(col("value")).as("ultimate_max_value")).orderBy(col("ultimate_max_value").desc)
summary2017: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [year(date): int, month(date): int ... 1 more field]

scala> summary2017.show
+----------+-----------+------------------+                                     
|year(date)|month(date)|ultimate_max_value|
+----------+-----------+------------------+
|      2017|          5|             649.0|
|      2017|          3|             639.0|
|      2017|          1|             639.0|
|      2017|          2|             617.0|
|      2017|          6|             610.0|
|      2017|          8|             600.0|
|      2017|          7|             544.0|
|      2017|          9|             501.0|
|      2017|          4|             500.0|
+----------+-----------+------------------+

Time taken: 41 secs.

scala> val combinedmaxtmeps = summary2020.join(summary2017, summary2020("month(date)")===summary2017("month(date)")).show
+----------+-----------+------------------+----------+-----------+------------------+
|year(date)|month(date)|ultimate_max_value|year(date)|month(date)|ultimate_max_value|
+----------+-----------+------------------+----------+-----------+------------------+
|      2020|          1|             644.0|      2017|          1|             639.0|
|      2020|          6|             500.0|      2017|          6|             610.0|
|      2020|          3|             485.0|      2017|          3|             639.0|
|      2020|          5|            2228.0|      2017|          5|             649.0|
|      2020|          9|             473.0|      2017|          9|             501.0|
|      2020|          4|             575.0|      2017|          4|             500.0|
|      2020|          8|             656.0|      2017|          8|             600.0|
|      2020|          7|             533.0|      2017|          7|             544.0|
|      2020|          2|             468.0|      2017|          2|             617.0|
+----------+-----------+------------------+----------+-----------+------------------+

Time taken : 1 min 17 secs.
